This project was created during our course on Machine Learning Methods for Language Processing and focuses on model exploration and training for machine translation.

For this project, we selected the WIT TED Talks dataset. After a series of data preparation steps, we created a bicleaned version to compare translation quality before and after bicleaning. We began by testing several ready-to-use models via the translation pipeline to obtain initial results. Based on these observations, we fine-tuned the T5-base and NLLB-200 models on our training data. 

After fine-tuning on our training data, both T5-base and NLLB-200 showed substantial improvement over their pre-training performance in translating TED Talk sentences. BLEU scores on the test set indicate that bicleaning the training data and including the Englishâ€“French direction improved translation quality for both models. When comparing them with each other, NLLB seems to perform slightly better than T5-base in all three variants. 

Nevertheless, analysis with compare-mt offered insights into word-level accuracy, sentence length matching, and translation performance across different sentence lengths. By combining these evaluation aspects, the baseline T5-base model trained on a pre-bicleaned dataset achieved the highest aggregate BLEU score, which also highlights the limitations of relying solely on a general BLEU score for evaluating machine translation quality. However, being English-centric and pretrained on limited languages, T5-base may not perform well on translations into English. For many-to-many translation, models trained on a diverse set of languages such as NLLB, which we fine-tuned in this project, may offer advantages in handling low-resource languages without relying on English as a pivot. Accordingly, we developed a training pipeline with extended hyperparameter tuning to support the exploration of other large multilingual models including mT5 and mBART50 and successfully conducted five trials with mT5 with a notable performance improvement.
