model_type: "t5"
model_name: "google/mt5-base"
tokenizer_name: "google/mt5-base"
seed: 42

train_dir: "/home/mlt_ml2/ML_Applied_Project_2025S/Data/chunk_files/"
val_dir: "/home/mlt_ml2/ML_Applied_Project_2025S/Data/chunk_files/"

source_lang: "en"
target_lang: "de"
prefix: "translate English to German: "

max_source_length: 128
max_target_length: 128

learning_rate: 5e-5
weight_decay: 0.01
num_train_epochs: 4
batch_size: 20
num_beams: 2

output_dir: "NMT_training_pipeline/outputs/mT5"
logging_dir: "NMT_training_pipeline/logs/mT5"
